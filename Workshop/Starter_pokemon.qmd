---
title: "Pokemon analysis"
author: "Your Name"
format: html
editor: visual
---

![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/International_Pok%25C3%25A9mon_logo.svg/1200px-International_Pok%25C3%25A9mon_logo.svg.png){fig-align="center"}

# Introduction

In this short hackathon you will analyse a Pokemon dataset. First, you will perform an exploratory analysis to get to know your data. Afterwards, you will develop a random forest model to predict the Pokemon type based on their characteristics.

# Project setup

Load libraries and import the Pokemon dataset. There is a nice defined color palette to color various Pokemon types. Include it in your visualizations.

```{r}
# List of required packages
required_packages <- c("dplyr","tidyr","ggplot2","ggstatsplot", "caret","ranger")

# Check if packages are installed and install them if not
for (package in required_packages) {
  if (!require(package, character.only = TRUE)) {
    install.packages(package, dependencies = TRUE)
    library(package, character.only = TRUE)
  }
}
# if you are missing any package install it
# import data and save it in pokemon variable
pokemon <- read.csv("pokemon.csv")
# make custom pokemon color palette
poke_palette <- c(	normal= '#A8A77A',	fire= '#EE8130',	water= '#6390F0',
              electric= '#F7D02C',	grass= '#7AC74C', 	ice= '#96D9D6',	
              fighting= '#C22E28',	poison= '#A33EA1',	ground= '#E2BF65',	
              flying= '#A98FF3',	psychic= '#F95587',	bug= '#A6B91A',
              rock= '#B6A136',	ghost= '#735797',	dragon= '#6F35FC',
              dark= '#705746',	steel= '#B7B7CE',	fairy= '#D685AD')
```

# Exploratory analysis

Perform an exploratory analysis of the dataset. Answer the following questions:

1.  How many Pokemon are in your dataset? How many of each type and generation?

```{r}
# Each pokemon is an observation in row. For counting use function nrow.

# One way we can approach it is to subset and count each of combination of type and generation. However, there is too many combinations. Therefore, we will use dplyr syntax to count. Fill in the missing values
pokemon %>%
  group_by(____, _____) %>%
  summarise(Count = n())
```

2.  How many numerical and how many categorical features you have in your data? Are all the numerical features continuous features? Explain.

    ```{r}
    ##### Solving using standard R functions
    # solving it using sapply
    vec_class <- sapply(____, ____)
    # counting how many do satisfy the condition
    table(vec_class != "____")

    ##### Using dpylr to solve this task
    # Check the data types of each column
    data_types <- pokemon %>%
      summarise_all(funs(___))

    # Count the number of numerical and categorical features
    numerical_features <- data_types %>%
      summarise(Count_Numerical = sum(. != "_____"),
                Count_Categorical = sum(. == "_____"))
    ```

3.  Visualize the distribution of Pokemon's statuses (attack ,defense, sp_attack, sp_defense, speed, weight_kg, hp and height_m) by type1 of Pokemon? What can you conclude?

```{r}
# Subset the dataset with the desired columns
selected_columns <- c(_____________________)
subset_poke <- pokemon %>% 
  select(all_of(selected_columns))

# Reshape the data using pivot_longer
poke_long <- pivot_longer(subset_poke,
                              cols = _____________)

# Create a boxplot
ggplot(poke_long, aes(x = type1, y = ________, fill=type1)) +
  geom_boxplot(show.legend = FALSE) +
  facet_wrap(~ ______, scales = "free_y") +
  theme_minimal() +
  scale_fill_manual(values=poke_palette)+
  theme(axis.text.x = element_text(angle=90))
```

4.  How correlated are the Pokemon's statuses? Which status features are highly correlated?

```{r}
# we will use ggcorrmat function from ggstatsplot package to get nive overview of correlation
# examine how you need to fill in the data
?ggcorrmat

```

5.  Against which type1 Pokemon are ice types the strongest? Use geom_violin for plot,

```{r}
 pokemon %>% 
      ggplot(., aes(x=_____, y=_____, fill=____)) +
      ____________(show.legend = FALSE) +
      scale_fill_manual(_____________) +
      theme_light() +
      labs(x="Pokemon type", y="Against ice") 
```

6.  Are legendary Pokemon heavier than non-legendary ones?

```{r}
# graphical solution using ggplot2
pokemon %>% 
      ggplot(., aes(x=__________, y=________)) +
      geom_boxplot() +
      theme_light() +
      labs(x="Legendary status")


# solution using base R
# mean for legendary pokemons
mean(pokemon[pokemon$____ == ___, ]$weight_kg)
# mean for non-legendary pokemons
mean(pokemon[pokemon$____ == ___, ]$weight_kg)
# why you get NA? Fix it

# perform t.test
t.test(_______________________, 
       _______________________)

```

7.  What type1 is most common for Mouse type Pokemon?

```{r}
    pokemon[grepl("_____", ______)] %>% 
      ggplot(., aes(x=_____, fill=_______)) +
      geom_bar(show.legend = FALSE) +
      theme_light() +
      scale_fill_manual(__________) +
      labs(x="Type of mouse pokemon")
```

8.  Perform any additional analysis you find most interesting about your favorite type or classification of Pokemon. Go wild!

# Predicting Pokemon type

## Cleaning data

We want to develop a machine learning model to predict the Pokemon type based on their statuses. Select only the "type1", "attack" ,"defense", "sp_attack", "sp_defense", "speed" "weight_kg", "hp" and "height_m" columns from the table. Remove any NAs present in the data using na.omit. Convert the type1 column to factor type.

```{r}
# define which caharacteristics you want to include in your modeling
vec_characteristics <- c()
# subesting data
pokemon_model <- pokemon %>% 
  ## fill in missing data
  _____

# removing NA
pokemon_model <- na.omit(pokemon_model)
# convert type1 to factor
pokemon_model$_____ <- as.factor(_____)
```

The first step in developing a model is to split the data into training and test set. Training set usually contains about 70-80 percent of data while test set contains 30-20 percent of the data. One of the most used R packages for statistical modeling is ***caret***. Install the package if you already do not have it.

1.  Search how to split the data into training and test set then do it.

    [caret package function for separating data](https://www.statology.org/createdatapartition-in-r/)

    ```{r}
     # split the data into training and test set
    library(caret)
    set.seed(3456)
    trainIndex <- createDataPartition(______)
    # visualize the index
    head(trainIndex)
    ## train and test
    pokeTrain <- pokemon_model[___,]
    pokeTest  <- pokemon_model[___,]
    ```

After you have split your data, you will develop a model using only test set and asses the performance of the model on the test set. Explain why is this approach necessary for model development?

Your answer: \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_.

2.  Examine which types of Pokemon are present in train and test sets? Do you see an class imbalance?

```{r}
# add a temporaty column indicating train and test set
pokeTrain$grp <- "train"
pokeTest$grp <- "test"
# exploratory analysis of Pokemon types in training and test sets
poke_ml_grp <- rbind(pokeTrain,
          pokeTest)

# vizualize
ggplot(_____, aes(x=_____, fill=_____)) +
      geom_bar(position="fill") +
      theme_light() +
      scale_fill_manual(values=poke_palette) +
      theme(legend.position = "top") +
      labs(x="Group", y="Pokemon type")
## chi-square test
chisq.test(_____________)

# remove grp
pokeTrain$grp <- NULL
pokeTest$grp <- NULL
```

## Random forest

For the development of the model you will use random forest. Caret package within function train has implemented random forest as a part of another package called ***ranger***. Ranger contains much faster implementation of random forest model that is why we are going to use this one.

1.  We will use random forest with 5 fold cross-validation approach which you need to define with function trainControl. Inside function *train* from caret package set the method argument to *ranger*, number of trees to 100 and importance to "permutation".

```{r}
# defining the cross-validation parameters
?trainControl
cntrl_par <- trainControl(method=_____,
                            number=______)
# run the model
pokeRF <- train(type1 ~ ., 
                data = _____, 
                method= _____, 
                trControl = _____,
                num.trees=_____, 
                importance=_____)
```

2.  Use function varImp to determine which variables are most important for your model.

```{r}
?varImp
```

3.  How well does your model perform when you test in on the test Pokemon dataset?

[Confusion matrix. Understand your outputs before deciding to convert them.](https://www.statology.org/confusion-matrix-in-r/)

```{r}
?confusionMatrix

confMatrix_res <- confusionMatrix(
  factor(predict(___, ___)),
  factor(___)
  )

confMatrix_res$table
```

# Conclusion

What did you learn from this short hackathon? Do you have any ideas how to improve the model?
